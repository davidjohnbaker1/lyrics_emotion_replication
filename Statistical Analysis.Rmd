---
title: "Statistical Analysis"
author: "David John Baker"
date: "July 6th 2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

This document provides the analysis for "Lyrics’ Emotional Influences in Songs: A Conceptual Replication of Ali and Peynircioğlu’s (2006) Study".
The script creates both figures for the paper as well as the statistical analysis.
This has been updated to reflect the second submission of the article. 

```{r}
# Libraries Needed 
library(ggridges)
library(ez)
library(multcomp)
library(lme4)
library(ggpubr)
library(sjPlot)
library(patchwork)
library(stringr)
library(dplyr)
library(magrittr)
library(readr)
library(ggplot2)
library(tidyr)
library(gt)

```

## Results to Replicate

* FIGURE 1: Replicate A+P 2006 Analysis of Experiment 1 and current experimental data
  - put main effects next to one another
  - add statistical significance 

```{r figureone}
#-------------------------------------------------------------------------------------------------
# AP Data Import 
table_1_values <- c(7.85, 8.18, 6.62, 6.91, 
                    5.79, 5.20, 6.51, 6.11, 
                    7.75, 7.95, 4.05, 5.41, 
                    5.00, 4.41, 6.08, 6.59)


sd(table_1_values)
# Function for Computing GRIM Tests

grim_test <- function(sample_size, likert_start, likert_end, means){
  integer_values <- sample_size * means
  bottom <- round(floor(integer_values)/ sample_size, 2)
  top <- round(ceiling(integer_values)/ sample_size, 2)
  df <- data.frame(bottom, top, means)
  df$sample_size <- sample_size
  df$possible <- ifelse(df$bottom == means | df$top == means, yes = TRUE,no = FALSE)
  df
  }

table_1 <- grim_test(32, 1, 9, table_1_values)

# Add in Factors for Original Data 
table_1$gender <- rep(c("Woman","Man"),8)
table_1$lyrics <- rep(c("No Lyric", "No Lyric", "Lyric","Lyric"),4)
table_1$emotions <- c(rep("Happy",4), rep("Sad",4), rep("Calm",4), rep("Angry",4))

# Add in Contrast for Valence 
table_1 <- table_1 %>%
  tibble() %>%
    mutate(valence = case_when(
    emotions == "Happy" ~ "Positive",
    emotions == "Calm" ~ "Positive",
    emotions == "Angry" ~ "Negative",
    emotions == "Sad" ~ "Negative"
  ))

# Values that match Table 1 , A + P 2006
table_1$emotions <- factor(table_1$emotions, levels = c("Happy","Calm","Angry","Sad"))

table_1

#-------------------------------------------------------------------------------------------------
# LSU Data Import 
df_complete <- read_csv("Complete_Data.csv", 
                        col_types = cols(age = col_character()))


df_complete %>%
  select(subject) %>%
  distinct() %>%
  tally()

129 - 21

# Drop Data 
df_complete <- df_complete %>%
  # REMOVE Pilot Data
  filter(subject > 21) %>%
  # REMOVE Non Native Speakers
  filter(!subject %in% c(38,53)) %>%
  # REMOVE Hearing Problems
  filter(!subject %in% c(43, 201, 204)) 

df_complete %>%
  select(subject) %>%
  distinct() %>%
  tally()


df_complete <- df_complete %>%
  mutate(age = str_replace_all(string = age, pattern = "eighteen", replacement = "18")) %>%
  mutate(age = str_replace_all(string = age, pattern = "3", replacement = NA_character_)) %>%
  mutate(age = as.numeric(age))

valence_table_exact <- read_csv("data/valence_sheet.csv")

df_complete %>% 
  left_join(valence_table_exact) %>%
  rename(track_valence = Valence) -> df_complete

df_complete <- df_complete %>%
   mutate(global_valence = case_when(
    track_valence == "Happy" ~ "Positive",
    track_valence == "Calm" ~ "Positive",
    track_valence == "AngryStressful" ~ "Negative",
    track_valence == "Sad" ~ "Negative"
  )) 

gender_table <- df_complete %>%
  select(subject, gender) %>%
  distinct() %>%
  mutate(gender = str_to_lower(gender)) %>%
  mutate(cleaned_gender = case_when(
    gender == "cis male" ~ "male",
    gender == "false" ~ NA_character_,
    gender == "female" ~ "female",
    gender == "femalen" ~ "female",
    gender == "male" ~ "male",
    gender == "malen" ~ "male"
  )) %>% 
  select(subject,cleaned_gender)
  
gender_table %>%
  group_by(cleaned_gender) %>%
  summarise(n = n())

df_complete %>%
  select(age) %>%
  summarise(mean = mean(age, na.rm = TRUE),
         sd = sd(age, na.rm = TRUE))

range(df_complete$age, na.rm = TRUE)

#---------------------------------------------------------------------------------------------------
# Main Effect of Intended Emotion
table_1 %>%
  group_by(emotions) %>%
  summarise(mean_ratings = mean(means))  %>%
  ggplot(aes(y = mean_ratings, 
             x = emotions)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(1,11)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  geom_bracket(
    xmin = c("Happy", "Happy","Happy"), xmax = c("Calm","Angry", "Sad"),
    y.position = c(8, 9, 10), label = c("t(126) = 5.95, p <.05 * ", "t(126) = 7.09, p <.05 *","t(126) = 3.92, p <.05 *"),
    tip.length = 0.05) +
  labs(title = "Original: Main Effect of Intended Emotion",
       subtitle = "F (3, 90) = 20.43, p < .001",
       x = "Intended Emotion",
       y = "Mean") +
  theme_minimal() -> me_intended_emotion

me_intended_emotion

# Main Effect of Valence
table_1 %>%
  group_by(valence) %>%
  summarise(mean_ratings = mean(means))  %>%
  ggplot(aes(y = mean_ratings, 
             x = valence)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(breaks = seq(1,9,1)) +
  coord_cartesian(ylim = c(1,9)) +
    geom_bracket(
    xmin = c("Negative"), xmax = c("Positive"),
    y.position = c(8), label = c("p < .001 ***"),
    tip.length = 0.05) +
  labs(title = "Original: Main Effect of Valence", subtitle = "F (1, 30) = 21.81, p < .001", y = "Mean") +
  theme_minimal() -> me_valence

me_valence

# Main Effect of Lyrics 
table_1 %>%
  group_by(lyrics) %>%
  summarise(mean_ratings = mean(means))  %>%
  ggplot(aes(y = mean_ratings, 
             x = lyrics)) +
  geom_bar(stat = "identity") +
  scale_y_continuous( breaks = seq(1,9,1)) +
  coord_cartesian(ylim = c(1,9)) +
    geom_bracket(
    xmin = c("Lyric"), xmax = c("No Lyric"),
    y.position = c(8), label = c("p < .01 **"),
    tip.length = 0.05) +
  labs(title = "Original: Main Effect of Lyrics", subtitle = "F (1, 30) = 11.81, p < .01", y = "Mean") +
  theme_minimal()  -> me_lyric

me_lyric

# NO Main Effect of Gender
# NOT Included in Manuscript 
table_1 %>%
  group_by(gender) %>%
  summarise(mean_ratings = mean(means))  %>%
  ggplot(aes(y = mean_ratings, 
             x = gender)) +
  geom_bar(stat = "identity") +
  labs(title = "Main Effect of Gender") +
  theme_minimal() -> me_gender

library(gridExtra)

foo <- grid.arrange(me_lyric, me_valence, nrow = 1)

#figure_1
foo2 <- grid.arrange(me_intended_emotion, foo, nrow = 2)


library(cowplot)

bottom_row <- plot_grid(me_lyric, me_valence, labels = c('B', 'C'))
top <- plot_grid(me_intended_emotion, labels = 'A')

cow_fig_1 <- plot_grid(top, bottom_row, ncol = 1)



ggsave(plot = foo2, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure1.png")

ggsave(plot = foo2, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure1.tiff")

ggsave(plot = cow_fig_1, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure1_labels.png")
ggsave(plot = cow_fig_1, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure1_labels.tiff")


#ggsave(plot = foo2, dpi = 300, filename = "img/Figure_1.tiff")

#------------------------------------------------------------------------------------

# Standard Deviation of Mean Function
std <- function(x) sd(x)/sqrt(length(x))

# Create Long Data, Subset Only Congruancy Conditions 
df_congruent <- df_complete %>%
  select(subject, Happy:AngryStressful, Condition, track_valence, global_valence) %>%
  left_join(gender_table) %>%
  pivot_longer(cols = Happy:AngryStressful, names_to = "response",values_to = "rating") %>%
  # Congrency Add Here!!
  mutate(congru = track_valence == response) %>%
  filter(congru == TRUE)

df_congruent[df_congruent$response == "AngryStressful",]$response <- "Angry"

df_congruent$response <- factor(df_congruent$response, levels = c("Happy","Calm","Angry","Sad"))

df_congruent


#---------------------------------------------------------------------------------------------------
# Main Effect of Intended Emotion
me_intended_emotion_lsu <- df_congruent %>%
  group_by(response) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = response, y = response_mean)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  coord_cartesian(ylim = c(1,12)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  # Significant Ratings Taken From Analysis Below 
  geom_bracket(
    xmin = c("Happy", "Happy","Happy","Calm","Angry"), 
    xmax = c("Calm","Angry","Sad","Angry","Sad"),
    y.position = c(9, 10, 11,8,9), label = c("***", "***","***","***","***"),
    tip.length = 0.05) +
    geom_errorbar(aes(ymin = response_mean + response_std, 
                      ymax = response_mean - response_std)) + 
  labs(title = "Main Effect of Emotion",
       x = "Emotion", y = "Mean Response")

me_intended_emotion_lsu

# Main Effect of Valence
me_valence_lsu <- df_congruent %>%
  group_by(global_valence) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  filter(!is.na(global_valence)) %>%
  ggplot(aes(x = global_valence, y = response_mean)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(1,9)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  geom_bracket(
    xmin = c("Negative"), 
    xmax = c("Positive"),
    y.position = c(7), label = c("***"),
    tip.length = 0.05) +
  geom_errorbar(aes(ymin = response_mean + response_std, 
                   ymax = response_mean - response_std)) + 
  theme_minimal() +
  labs(title = "Main Effect of Valence",  x = "Emotion", y = "Mean Response")

me_valence_lsu

# Main Effect of Lyrics
me_lyrics_lsu <- df_congruent %>%
  group_by(Condition) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = Condition, y = response_mean)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(1,9)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  geom_bracket(
    xmin = c("Lyrics"), 
    xmax = c("Melody"),
    y.position = c(7), label = c("***"),
    tip.length = 0.05) +
  theme_minimal() +
  geom_errorbar(aes(ymin = response_mean + response_std, 
                    ymax = response_mean - response_std)) + 
  labs(title = "Main Effect of Condition", y = "Mean Response")

me_lyrics_lsu

# Main Effect of Gender 
me_gender_lsu <- df_congruent %>%
  left_join(gender_table) %>%
  group_by(cleaned_gender) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = cleaned_gender, y = response_mean)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  geom_errorbar(aes(ymin = response_mean + response_std, 
                    ymax = response_mean - response_std)) + 
  labs(title = "Main Effect of Gender")


conditions <- grid.arrange(me_lyrics_lsu, me_valence_lsu, nrow = 1)

foo3 <- grid.arrange(me_intended_emotion_lsu, conditions, nrow = 2)


ggsave("img/lsue_effects.png", foo3, height = 5, width = 9)

# Figure Save 
ggsave("img/Figures/Figure2.tiff", dpi = 300, foo3, height = 5, width = 9)



#(lsu_panel <- (me_intended_emotion_lsu | me_valence_lsu) / (me_lyrics_lsu | me_gender_lsu))


```

```{r}
# Big Plots of LSU 
# Make Mean Rating Per Condition 
df_congruent  %>%
  left_join(gender_table) %>%
  group_by(Condition, response) %>%
  summarise(mean_rating = mean(rating),
            sd_rating = sd(rating),
            max_rating = max(rating),
            min_rating = min(rating),
            se_rating = std(rating),
            number_of_ratings = n()) %>%
  mutate(response = factor(response, levels = c("Happy","Calm","Angry","Sad"))) %>%
  mutate(valence = case_when(
    response == "Angry" ~ "Negative",
    response == "Sad" ~ "Negative",
    response == "Happy" ~ "Positive",
    response == "Calm" ~ "Positive"
    
  )) %>%
  ggplot(aes(x = response, y = mean_rating, fill = valence)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Condition) +
  geom_errorbar(aes(ymin = mean_rating + se_rating, ymax = mean_rating - se_rating)) + 
  labs(title = "Mean Ratings",
       caption = "Error Bars represent Standard Error of Mean",
       x = "Response Category",
       y = "Mean Rating",
       fill = "Valence") +
  theme_bw()  +      
  scale_fill_manual(values = c("grey1","grey30")) -> all_lsu_valence

all_lsu_valence

ggsave(filename = "img/all_lsu_valence.png", all_lsu_valence, height = 5, width = 9)

ggsave(filename = "img/Figures/Figure3.tiff", dpi = 300, all_lsu_valence, height = 5, width = 9)


```

## Analysis

### Data Cleaning 

### Hypothesis 1

Our first analysis sought to re-create our 4 x 2 x 2 factorial repeated measures ANOVA.

```{r}
# As ANOVA 
df_replicate_anova <- df_congruent
df_replicate_anova <- df_replicate_anova %>%
  rename(Lyrics = Condition, 
         Emotion = response,
         Gender = cleaned_gender)

df_replicate_anova

factorial_anova_direct_replication <- ezANOVA(
  data = df_replicate_anova
  , dv = .(rating)
  , wid = .(subject)
  , within = .(Lyrics, Emotion)
  , between = .(Gender),
  type = 3, # Do you want to do Type III sum of Squares, doesnt change results...
  detailed = TRUE,
  return_aov = TRUE
)

# Check Exlusion Criteria from Pre-Registration since this is on border
print(factorial_anova_direct_replication)

df_replicate_anova %>%
  group_by(Emotion) %>%
  summarise(mean = mean(rating, na.rm = TRUE),
            sd = sd(rating, na.rm = TRUE))

df_replicate_anova %>%
  group_by(Lyrics) %>%
  summarise(mean = mean(rating, na.rm = TRUE),
            sd = sd(rating, na.rm = TRUE))



apaTables::apa.ezANOVA.table(factorial_anova_direct_replication) #, filename = "tables/table_1.doc")


library(lmerTest)
library(multcomp)

hypothesis_1_model <- lmer(rating ~ Lyrics*Gender*Emotion + (1|subject), data = df_replicate_anova)

# ANOVA Table 
anova(hypothesis_1_model)

# Linear Model Output 
summary(hypothesis_1_model)

# Main Effects of Emotions
summary(glht(hypothesis_1_model, linfct=mcp(Emotion = "Tukey")), test = adjusted(type = "bonferroni"))

summary(glht(hypothesis_1_model, linfct=mcp(Lyrics = "Tukey")), test = adjusted(type = "bonferroni"))

# Grouped Valence Analysis (should have been contrast)

df_replicate_anova

factorial_anova_direct_replication_valence <- ezANOVA(
  data = df_replicate_anova
  , dv = .(rating)
  , wid = .(subject)
  , within = .(global_valence),
  #, between = .(Gender),
  type = 3, # Do you want to do Type III sum of Squares, doesnt change results...
  detailed = TRUE,
  return_aov = TRUE
)

print(factorial_anova_direct_replication_valence)

apaTables::apa.ezANOVA.table(factorial_anova_direct_replication_valence) #, filename = "tables/table_1.doc")


df_replicate_anova %>%
  group_by(global_valence) %>%
  summarise(mean = mean(rating, na.rm = TRUE),
            sd = sd(rating, na.rm = TRUE))

```

In order to investigate our first research question, we conducted a 4 x 2 x 2 factorial repeated-measures ANOVA using the ez package in the R programming language (R Core Team, 2020) corrected with Greenhouse-Geisser to examine the influence three independent variables (lyics, emotions, gender) on ratings of emotion. Our lyrics condition contained two levels (lyrics, no-lyrics), our emotions condition contained four levels (happy, sad, calm, angry), and our gender variable contained two levels (female and male). We note that due to the uneven number of men and women in the sample, our ANOVA used Type III sum-of-squares. Our analysis adopted the conventional alpha level of .05 to assert statistical significance. We report only a main effect of gender and lyrics, with no significant main effect of gender or any interactions.  The main effect of emotions yielded an F ratio of F(3, 264.30) = 28.24, p <.001, ges = .11 indicating a significant difference between happy (M = 5.10  , SD = 2.71 ), sad (M = 6.06, SD = 2.52), calm (M = 6.63 , SD = 1.98), and angry (M = 5.56, SD = 2.98) emotions. The main effect of lyrics yielded an F ratio of F(1, 102) =203.46, p <.001 indicating a significant difference between ratings of songs with lyrics ( M = 6.34 , SD = 2.52 ) and without lyrics ( M = 5.34 , SD = 2.64). No other effects were significant (ps > .05). 
We followed up on our main effects of both Emotions and Lyrics using a Tukey HSD test  implemented in the multcomp package in R (Hothorn et al., 2014). We report significant differences (p <.05) in the Emotion condition between all pairs of emotions with the exception of sad and calm. We also report a significant pairwise difference between the lyrics condition (p < .05) as shown in Figure 2. 


```{r}
# Figure 2 
df_replicate_anova 

top_replication <- df_replicate_anova %>%
  group_by(Emotion) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = Emotion, y = response_mean)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  coord_cartesian(ylim = c(1,12)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  # Significant Ratings Taken From Analysis Below 
  geom_bracket(
    xmin = c("Happy", "Happy","Happy","Calm","Angry"), 
    xmax = c("Calm","Angry","Sad","Angry","Sad"),
    y.position = c(9, 10, 11,8,9), label = c("***", "***","***","***","***"),
    tip.length = 0.05) +
    geom_errorbar(aes(ymin = response_mean + response_std, 
                      ymax = response_mean - response_std)) + 
  labs(title = "Replication: Main Effect of Intended Emotion",
       subtitle = "F (3, 264.30) = 28.24, p <.001",
       x = "Emotion", y = "Mean Response")

bot_left_replication <- df_replicate_anova %>%
  mutate(Lyrics = str_replace_all(Lyrics, pattern = "Melody", "No Lyrics")) %>%
  group_by(Lyrics) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = Lyrics, y = response_mean)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  coord_cartesian(ylim = c(1,9)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  # Significant Ratings Taken From Analysis Below 
  geom_bracket(
    xmin = c("Lyrics"), 
    xmax = c("No Lyrics"),
    y.position = c(7), label = c("***"),
    tip.length = 0.05) +
    geom_errorbar(aes(ymin = response_mean + response_std, 
                      ymax = response_mean - response_std)) + 
  labs(title = "Replication: Main Effect of Lyrics",
       subtitle = "F (1, 102) = 203.46, p <.001",
       x = "Lyrics", y = "Mean Response")

bot_right_rep <- df_replicate_anova %>%
  group_by(global_valence) %>%
  summarise(
    response_mean = mean(rating),
    response_sd = sd(rating),
    response_std = std(rating)
  ) %>%
  ggplot(aes(x = global_valence, y = response_mean)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  coord_cartesian(ylim = c(1,9)) +
  scale_y_continuous( breaks = seq(1,9,1)) +
  # Significant Ratings Taken From Analysis Below 
  geom_bracket(
    xmin = c("Positive"), 
    xmax = c("Negative"),
    y.position = c(7), label = c("n.s"),
    tip.length = 0.05) +
    geom_errorbar(aes(ymin = response_mean + response_std, 
                      ymax = response_mean - response_std)) + 
  labs(title = "Replication: Main Effect of Valence",
       subtitle = "F (1, 103) = .08, p > .05",
       x = "Valence", y = "Mean Response")

topper_rep <- plot_grid(top_replication, labels = "A")
bottom_rep <- plot_grid(bot_left_replication, bot_right_rep, labels = c("B","C"))

figure2 <- plot_grid(topper_rep, bottom_rep, ncol = 1)

ggsave(plot = figure2, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure2_labels.png")
ggsave(plot = figure2, height = 6, width = 9, dpi = 300, filename = "img/Figures/Figure2_labels.tiff")

```




### Hypothesis 2

Correlational analysis of musical training.

```{r}
df_complete %>%
  select(subject, MUSICAL, EMOTIONS) %>%
  distinct() -> gmsi_table

df_congruent %>%
  left_join(gmsi_table) -> emotion_rating_table

gmsi_cor <- function(data, gmsi_tab, emotion, gmsi){
  data %>%
    filter(response == emotion) %>%
    select(subject, rating, gmsi) %>%
    group_by(subject) %>%
    summarise(avg_emo = mean(rating)) %>%
    left_join(gmsi_tab) %>%
    select(avg_emo, gmsi)
}

#--------------------------------------------------------
# Musical 
happy_musical <- gmsi_cor(emotion_rating_table, gmsi_table, "Happy", "MUSICAL")
cor.test(happy_musical$avg_emo, happy_musical$MUSICAL)

sad_musical <- gmsi_cor(emotion_rating_table, gmsi_table, "Sad", "MUSICAL")
cor.test(sad_musical$avg_emo, happy_musical$MUSICAL)

calm_musical <- gmsi_cor(emotion_rating_table, gmsi_table, "Calm", "MUSICAL")
cor.test(calm_musical$avg_emo, happy_musical$MUSICAL)

angry_musical <- gmsi_cor(emotion_rating_table, gmsi_table, "Angry", "MUSICAL")
cor.test(angry_musical$avg_emo, happy_musical$MUSICAL)
#--------------------------------------------------------
# Emotional
happy_emotions<- gmsi_cor(emotion_rating_table, gmsi_table, "Happy", "EMOTIONS")
cor.test(happy_emotions$avg_emo, happy_emotions$EMOTIONS)

sad_emotions <- gmsi_cor(emotion_rating_table, gmsi_table, "Sad", "EMOTIONS")
cor.test(sad_emotions$avg_emo, sad_emotions$EMOTIONS)

calm_emotions <- gmsi_cor(emotion_rating_table, gmsi_table, "Calm", "EMOTIONS")
cor.test(calm_emotions$avg_emo, calm_emotions$EMOTIONS)

angry_emotions <- gmsi_cor(emotion_rating_table, gmsi_table, "Angry", "EMOTIONS")
cor.test(angry_emotions$avg_emo, angry_emotions$EMOTIONS)


# Make 4 x 2 Panel with Linear Models 
library(ggpubr)
library(purrr)

# Make Data 
emotion_rating_table %>%
  select(subject, rating, response) %>%
  group_by(subject,response) %>%
  summarise(avg_rating = mean(rating)) %>%
  left_join(gmsi_table) %>%
  ungroup(subject, response) %>%
  mutate(z_musical = scale(MUSICAL), z_emotions = scale(EMOTIONS)) %>%
  pivot_longer(cols = z_musical:z_emotions, names_to = "Emotion", values_to = "GMSI") %>%
  group_by(Emotion, response) %>%
  nest() %>%
  mutate(Mod = map(data, ~lm(avg_rating ~ GMSI, data = .x))) %>%
  mutate(R2 = map_dbl(Mod, ~round(summary(.x)$r.squared, 3)),
         p = map_dbl(Mod, ~round(summary(.x)$coefficients[8], 4))) -> correl_sum_stats

correl_sum_stats %>%
  select(response, Emotion, R2, p)

#%>%
#  select(response, Emotion, R2, p) -> correlation_summary_stats

emotion_rating_table %>%
  select(subject, rating, response) %>%
  group_by(subject,response) %>%
  summarise(avg_rating = mean(rating)) %>%
  left_join(gmsi_table) %>%
  ungroup(subject, response) %>%
  mutate(`Musical GMSI` = scale(MUSICAL), `Emotions GMSI` = scale(EMOTIONS)) %>%
  pivot_longer(cols = `Musical GMSI`:`Emotions GMSI`, names_to = "Emotion", values_to = "GMSI") %>%
  group_by(Emotion, response) %>%
# Make Plot 
  ggplot(aes(x = avg_rating, y = GMSI, shape = Emotion, linetype = Emotion)) +
  geom_point(size = 1.5) +
  scale_shape_manual(name = "Data", values=c(1,4)) +
  scale_linetype_manual(name = "Model", values=c(3,1)) +
  geom_smooth(method = "lm", se = FALSE, color = "black", aes(linetype = Emotion)) +
  theme_bw() +
  facet_wrap(~response) +
  labs(title = "Average Rating Per Emotion vs Gold-MSI", x = "Average Rating", y = "Standardized GMSI Score of Individual") -> cor_plots_gmsi

cor_plots_gmsi

ggsave(filename = "img/cor_plots.png", cor_plots_gmsi, units = "cm", dpi = 300, height = 10, width = 20)  

# Figure Save 
ggsave(filename = "img/Figures/Figure4.tiff", cor_plots_gmsi, units = "cm", dpi = 300, height = 10, width = 20)  

```


Expanding for Mixed Effects

```{r}

df_congruent %>%
  left_join(gmsi_table)  -> model_2_data

hypothesis_2_model <- lmerTest::lmer(rating ~ Condition*response + MUSICAL + EMOTIONS + (1|subject), data = model_2_data)

summary(hypothesis_2_model)

sjPlot::tab_model(hypothesis_2_model)
```


### Hypothesis 3

(Removed for Publication)

```{r}
hypothesis_3_model <- lmerTest::lmer(rating ~ global_valence + (1|subject), data = df_replicate_anova)

# ANOVA Table 
anova(hypothesis_3_model)

# Linear Model Output 
summary(hypothesis_3_model)

df_replicate_anova %>%
  group_by(global_valence) %>%
  summarise(mean = mean(rating),
            sd= sd(rating))

```

### Familiarity Check

```{r}
df_complete %>%
  select(subject, MUSICAL, EMOTIONS, Familiar) %>%
  distinct() -> gmsi_table_2

df_congruent %>%
  left_join(gmsi_table_2) -> max_model_data

hypothesis_4_model <- lmerTest::lmer(rating ~ Condition*response + MUSICAL + EMOTIONS + Familiar + (1|subject), data = max_model_data)


# ANOVA Table 
anova(hypothesis_4_model)

# Linear Model Output 
summary(hypothesis_4_model)

tab_model(hypothesis_4_model)
```

